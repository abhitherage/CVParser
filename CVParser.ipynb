{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "ABHISHEK\tSAHU\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tabhishek.sahu0724@gmail.com\t\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "EDUCATION\t\n",
      "2016\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\n",
      "2012\t\n",
      "\t\n",
      "2010\t\n",
      "\t\n",
      "\t\n",
      "SKILLS\tAND\tINTERESTS\t\n",
      "\n",
      "Indian\tInstitute\tof\tTechnology\t(BHU),\tVaranasi\t\n",
      "B.\tTech\tin\tCeramic\tEngineering,\tCGPA:\t7.68\t\n",
      "Dreamland\tHr\tSec\tSchool,\tBilaspur\t\n",
      "CGBSE\t12th,\t85.20%\t\n",
      "Jawahar\tNavodaya\tVidyalaya,\tBilaspur\t\n",
      "CBSE\t10th,\tCGPA:\t9.8\t\n",
      "\n",
      "+91\t7828235708\t\n",
      "\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "▪\tKey\tSkills:\tProject\tManagement,\tBusiness\tAnalytics,\tand\tOperations\t&\tManagement\t\n",
      "▪\tTechnical\tSkills:\tMS\tOffice,\tSQL\t,\tR\t(basics),\tGoogle\tAnalytics\t\n",
      "\n",
      "\t\n",
      "EXPERIENCE\t\t\n",
      "May’17\t–\tJuly’18\t\n",
      "\n",
      "\t\n",
      "July’16\t-\tApril’17\t\t\n",
      "\n",
      "INTERNSHIP\t\n",
      "May\t-\tJune,\t2015\t\n",
      "\n",
      "\t\n",
      "May\t-\tJune,\t2014\t\n",
      "\n",
      "\t\n",
      "STARTUP\t\n",
      "July’13\t-\tApril’14\t\t\n",
      "\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "Assistant\tManager\t–\tOYO\t\n",
      "▪\tPerformed\tin\tdepth\tbusiness\tanalysis\tto\timprove\tkey\tmetrics\tof\tthe\tInbound\t&\tOutbound\tSales\t\n",
      "Business\t(Monthly\tRevenue\t>\t200\tMn)\t\n",
      "▪\tSuccessfully\timplemented\tProcess\tImprovement\t&\tExpansion,\tProduct\tEnhancement\tprojects\t\n",
      "resulting\tin\t6X\trevenue\tgrowth\t(in\tOutbound\tSales\tChannel)\tin\t12\tmonths\t\n",
      "▪\tBuilt\tmulti-level\tMetric\tPerformance\tDashboards\tto\ttrack\tkey\tbusiness\tmetrics\t\n",
      "\n",
      "Consultant\t-\tIndian\tPolitical\tAction\tCommittee\t(I-PAC)\t\t\t\t\t\t\n",
      "▪\t Managed\t on-ground\t campaigns\t by\t building\t and\t leading\t teams\t to\t achieve\t maximum\t public\t\n",
      "outreach\tin\tPunjab\t&\tUP\t\n",
      "▪\tDesigned\tinnovative\tpublic\toutreach\tand\tengagement\tcampaigns,\twith\tcomplete\tturn-\taround\t\n",
      "of\telection\tcampaigning\tacross\tPunjab\t&\tUP\t\t\n",
      "▪\tPerformed\tdata\tanalysis\tof\tpast\telections\tand\texecuted\tsocial\tmedia\toutreach\tcampaigns\t\t\n",
      "\t\n",
      "\n",
      "General\tManagement\tTrainee\t-\tThe\tElitists\t\t\t\t\t\t\t\t\t\t\n",
      "▪\tPerformed\tQualitative\tBusiness\tResearch,\tAnalysis\tand\tExecutive\tTalent\tMapping\tfor\tBusiness\t\n",
      "Development\t\n",
      "\n",
      "Summer\tTrainee\t-\tIndian\tInstitute\tof\tManagement,\tAhmedabad\t\n",
      "▪\tOrganized\t‘Scholars\tfor\tChange’\tCampaign\tacross\tIndia\tfocussed\ton\tcreating\tan\telectronic\tlibrary\t\n",
      "of\teducational\tvideos\tfor\tunderprivileged\tstudents\t\t\n",
      "\t\n",
      "Core\tTeam\tMember\t-\tInternlelo\t\n",
      "▪\tResponsible\tfor\tMarket\tResearch,\tContent\tCuration\tand\tTeam\tExpansion\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "▪\t Volunteered\t at\t ‘Kashi\t Utkarsh’,\t for\t cause\t of\t Education,\t Health\t and\t Hygiene\t in\t slum\t areas\t of\t\n",
      "Varanasi\t\n",
      "▪\tMarketing\tHead\t-\tNGO\tAssociation\tand\tCo-ordinator\t-\tInformal\tEvents\tat\tTechnex\t\n",
      "▪\tSelected\tas\ta\tYatri\tfor\tJagriti\tYatra\t(2014)\t\n",
      "▪\tSecured\t3rd\tposition\tin\tStock\tMarket\tCompetition\torganized\tby\tDalal\tStreet\t\n",
      "▪\tAwarded\tconsolation\tprize\tin\tCase\tStudy\tCompetition\torganized\tby\tIMS\tVaranasi\t\n",
      "\n",
      "\t\n",
      "ACHIEVEMENTS\tAND\tACTIVITIES\t\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "# To extract pdf files\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(extract_text_from_pdf('abhishek.sahu0724.gmail@naukri.comabhishekDotsahuDotcer12@iitbhuDotacDotin.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akash Gupta   \n",
      "\n",
      "    Email: akash.gupta13920@gmail.com\n",
      "\n",
      "Mobile: +91-8743890753\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Objectives\n",
      "\n",
      "Seeking employment with an organization where I can utilize my skills and knowledge efficiently to achieve personal as well as organizational goals\n",
      "\n",
      "\n",
      "\n",
      "     \n",
      "\n",
      "Career Summary \n",
      "\n",
      "  Organization\n",
      "\n",
      "  Period\n",
      "\n",
      "  Role\n",
      "\n",
      "  Nucleus Software Exports Private Ltd.\n",
      "\n",
      "  Sept, 2015 – till date\n",
      "\n",
      "  Senior Solution Analyst\n",
      "\n",
      "      \n",
      "\n",
      "Work Experience \n",
      "\n",
      "Company \n",
      "\n",
      "Nucleus Software Exports Private Ltd.\n",
      "\n",
      "Duration \n",
      "\n",
      "Sep, 2015 – till date\n",
      "\n",
      "Role & Responsibilities\n",
      "\n",
      " \n",
      "\n",
      "Analysis of the business requirements and delivering the same to the development team  .\n",
      "\n",
      "Creating insightful reports for the clients.\n",
      "\n",
      "Provided best possible solution to the client requirements.\n",
      "\n",
      "Product implementation at the client side.\n",
      "\n",
      "Product review meetings with client..\n",
      "\n",
      "Currently Working for VCCB , Vietnam.\n",
      "\n",
      "\n",
      "\n",
      " Rewards and Acknowledgement \n",
      "\n",
      "Appreciation Award for good work at the project level.\n",
      "\n",
      "\n",
      "\n",
      "Skills Set \n",
      "\n",
      "Languages \n",
      "\n",
      "  R,SQL,SAS\n",
      "\n",
      "Software Tool \n",
      "\n",
      "MS Office, MS excel , Open office ,\n",
      "\n",
      "Database\n",
      "\n",
      "Oracle 10g\n",
      "\n",
      " \n",
      "\n",
      "Academic Details \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Year \n",
      "\n",
      "    Degree \n",
      "\n",
      "\n",
      "\n",
      "Institute \n",
      "\n",
      "Percentage\n",
      "\n",
      "2015 \n",
      "\n",
      " \n",
      "\n",
      "            B.Tech \n",
      "\n",
      "Electronics and Communication\n",
      "\n",
      " \n",
      "\n",
      "Vellore Institute of Technology,Tamil Nadu\n",
      "\n",
      "87.1\n",
      "\n",
      " \n",
      "\n",
      "2010 \n",
      "\n",
      "                 Class XII\n",
      "\n",
      "   CBSE Board\n",
      "\n",
      "\n",
      "\n",
      "St. Andrews Sr. Secondary School,Agra\n",
      "\n",
      "72.00\n",
      "\n",
      "2008 \n",
      "\n",
      "           Class X\n",
      "\n",
      "   CBSE Board\n",
      "\n",
      "\n",
      "\n",
      "Doon International School,Dehradun\n",
      "\n",
      "82.00\n",
      "\n",
      " \n",
      "\n",
      "Declaration: \n",
      "\n",
      "I hereby declare that the above written particulars are true to the best of my knowledge.\n"
     ]
    }
   ],
   "source": [
    "# To extract docs and other format files\n",
    "import docx2txt\n",
    "\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    txt = docx2txt.process(docx_path)\n",
    "    if txt:\n",
    "        return txt.replace('\\t', ' ')\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(extract_text_from_docx('akash.gupta13920.gmail@naukri.comakashDotgupta13920@gmailDotcom.docx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akash\n"
     ]
    }
   ],
   "source": [
    "# To extract name from resume\n",
    "\n",
    "import docx2txt\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    txt = docx2txt.process(docx_path)\n",
    "    if txt:\n",
    "        return txt.replace('\\t', ' ')\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_names(txt):\n",
    "    person_names = []\n",
    "\n",
    "    for sent in nltk.sent_tokenize(txt):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
    "                person_names.append(\n",
    "                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n",
    "                )\n",
    "\n",
    "    return person_names\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_docx('akash.gupta13920.gmail@naukri.comakashDotgupta13920@gmailDotcom.docx')\n",
    "    names = extract_names(text)\n",
    "\n",
    "    if names:\n",
    "        print(names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abhishek.sahu0724@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# To extract email from resume\n",
    "\n",
    "import re\n",
    "\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "\n",
    "def extract_emails(resume_text):\n",
    "    return re.findall(EMAIL_REG, resume_text)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_pdf('abhishek.sahu0724.gmail@naukri.comabhishekDotsahuDotcer12@iitbhuDotacDotin.pdf')\n",
    "    emails = extract_emails(text)\n",
    "\n",
    "    if emails:\n",
    "        print(emails[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Academic Details Year Degree Institute', 'Communication Vellore Institute'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "\n",
    "RESERVED_WORDS = [\n",
    "    'school',\n",
    "    'college',\n",
    "    'univers',\n",
    "    'academy',\n",
    "    'faculty',\n",
    "    'institute',\n",
    "    'faculdades',\n",
    "    'Schola',\n",
    "    'schule',\n",
    "    'lise',\n",
    "    'lyceum',\n",
    "    'lycee',\n",
    "    'polytechnic',\n",
    "    'kolej',\n",
    "    'ünivers',\n",
    "    'okul',\n",
    "]\n",
    "\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    txt = docx2txt.process(docx_path)\n",
    "    if txt:\n",
    "        return txt.replace('\\t', ' ')\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_education(input_text):\n",
    "    organizations = []\n",
    "\n",
    "    # first get all the organization names using nltk\n",
    "    for sent in nltk.sent_tokenize(input_text):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'ORGANIZATION':\n",
    "                organizations.append(' '.join(c[0] for c in chunk.leaves()))\n",
    "\n",
    "    # we search for each bigram and trigram for reserved words\n",
    "    # (college, university etc...)\n",
    "    education = set()\n",
    "    for org in organizations:\n",
    "        for word in RESERVED_WORDS:\n",
    "            if org.lower().find(word) >= 0:\n",
    "                education.add(org)\n",
    "\n",
    "    return education\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_docx('akash.gupta13920.gmail@naukri.comakashDotgupta13920@gmailDotcom.docx')\n",
    "    education_information = extract_education(text)\n",
    "\n",
    "    print(education_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
